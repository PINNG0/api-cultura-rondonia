from scraping.runner import scrape_all
from scraping.storage import save_only
from scraping.config import LOCKFILE
from scraping.archiver import ArquivadorEventos
from scraping.html_generator import gerar_html_arquivos_por_ano
import os
import json
import hashlib

def rodando_no_github():
    return os.getenv("CI") == "true" or os.getenv("GITHUB_ACTIONS") == "true"

def gerar_hash_eventos(eventos):
    """
    Gera um hash √∫nico considerando TODOS os campos relevantes do evento.
    Agora o hash √© 100% determin√≠stico mesmo em ordem diferente.
    """
    # serializa tudo com chaves ordenadas
    payload = json.dumps(eventos, ensure_ascii=False, sort_keys=True)
    return hashlib.sha256(payload.encode("utf-8")).hexdigest()

if __name__ == "__main__":
    ignorar_lock = rodando_no_github()

    if os.path.exists(LOCKFILE) and not ignorar_lock:
        print("‚ö†Ô∏è J√° est√° rodando. Abortando.")
        exit(1)

    print("üöÄ Iniciando raspagem de eventos...")

    try:
        with open(LOCKFILE, 'w') as f:
            f.write("running")

        eventos = scrape_all()
        print(f"‚úÖ Raspagem conclu√≠da. Eventos coletados: {len(eventos)}")

        print("üíæ Salvando arquivos...")
        save_only(eventos)

        print("üßπ Arquivando eventos antigos...")
        ArquivadorEventos().arquivar()

        print("üß© Atualizando index.html...")
        index_path = "docs/index.html"
        index_modificado = False

        if os.path.exists(index_path):
            with open(index_path, "r", encoding="utf-8") as f:
                conteudo = f.read()

            html_anos = gerar_html_arquivos_por_ano()
            if "<!-- anos -->" in conteudo:
                novo_conteudo = conteudo.split("<!-- anos -->")[0] + "<!-- anos -->\n" + html_anos
                if novo_conteudo != conteudo:
                    index_modificado = True
                    with open(index_path, "w", encoding="utf-8") as f:
                        f.write(novo_conteudo)
                    print("‚úÖ index.html atualizado!")
                else:
                    print("‚úî index.html sem mudan√ßas.")
            else:
                print("‚ö†Ô∏è Marcador <!-- anos --> n√£o encontrado no index.html.")
        else:
            print("‚ö†Ô∏è index.html n√£o encontrado.")

        # ----- DETEC√á√ÉO DE MUDAN√áAS -----
        print("üîé Verificando mudan√ßas nos dados...")

        novo_hash = gerar_hash_eventos(eventos)
        hash_path = ".cache/hash_eventos.txt"
        os.makedirs(".cache", exist_ok=True)

        antigo_hash = None
        if os.path.exists(hash_path):
            with open(hash_path, "r", encoding="utf-8") as f:
                antigo_hash = f.read().strip()

        mudou_eventos = antigo_hash != novo_hash

        if mudou_eventos:
            print("üìå Dados dos eventos mudaram.")
        else:
            print("‚úî Eventos iguais ao √∫ltimo hash salvo.")

        # Salva o novo hash (IMPORTANTE: sempre salvar ap√≥s a execu√ß√£o)
        with open(hash_path, "w", encoding="utf-8") as f:
            f.write(novo_hash)

        # LOG FINAL
        if mudou_eventos or index_modificado:
            print("üì§ Mudan√ßas detectadas. O GitHub Actions ir√° comitar.")
        else:
            print("üü° Nenhuma mudan√ßa detectada. O GitHub Actions n√£o enviar√° commit.")

        print("üéâ Processo finalizado com sucesso!")

    finally:
        if os.path.exists(LOCKFILE):
            os.remove(LOCKFILE)
